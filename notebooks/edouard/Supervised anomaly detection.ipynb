{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Debug mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For relative imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading observation A1\n",
      "Loading observation A2\n",
      "Loading observation B1\n",
      "Loading observation B2\n",
      "Loading observation C1\n",
      "Loading observation C2\n",
      "Loading observation D1\n",
      "Loading observation D2\n",
      "Loading observation E1\n",
      "Loading observation E2\n",
      "Loading observation F1\n",
      "Loading observation F2\n",
      "Loading observation G1\n",
      "Loading observation G2\n",
      "Loading observation H1\n",
      "Loading observation H2\n",
      "Loading observation B3\n",
      "Loading observation B4\n",
      "Loading observation F3\n",
      "Loading observation F4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import mpld3\n",
    "from interval import Interval\n",
    "from observation import Observation\n",
    "from constants import *\n",
    "from datetime import timedelta\n",
    "from tools import sequence_to_interval\n",
    "plt.style.use('ggplot')\n",
    "mpld3.enable_notebook()\n",
    "\n",
    "PATH = \"../../../Data/GMPP_IRSDI/\"\n",
    "reactor_sites = [site+tranche for site in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"] for tranche in [\"1\",\"2\"]] + [\"B3\",\"B4\",\"F3\",\"F4\"]\n",
    "\n",
    "suffixes = [\n",
    "\"DEB1-1\",\"DEB1-2\",\"DEB1-3\"#,\"DEB1-4\", # Débit de fuite au joint 1 (Gamme Large)\n",
    "# \"DEB2-1\",\"DEB2-2\",\"DEB2-3\",\"DEB2-4\", # Débit de fuite au joint 1 (Gamme Étroite)\n",
    "# \"DEB3-1\",\"DEB3-2\",\"DEB3-3\",\"DEB3-4\",\"DEB3-5\", # Débit d'injection au joint\n",
    "# \"PUI-\",  # Puissance thermique moyenne\n",
    "# \"PRE-\",  # Pression\n",
    "# \"TEM1-\", # Température ligne d'injection aux joints (en * Celsius) ### A rapprocher de DEB3\n",
    "# \"TEM2-\", # Température fuites joint 1\n",
    "# \"TEM3-1\",\"TEM3-2\",\"TEM3-3\",\"TEM3-4\",# Température eau joint 1 - 051PO ### A rapprocher de DEB1 DEB2\n",
    "# \"VIT-1\",\"VIT-2\",\"VIT-3\",\"VIT-4\"# Vitesse de rotation\n",
    "] \n",
    "\n",
    "obs_dict = {}\n",
    "\n",
    "for reactor_site in reactor_sites:\n",
    "    print(\"Loading observation \"+reactor_site)\n",
    "    obs_dict[reactor_site] = Observation(PATH,reactor_site,suffixes,verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re- exectute that everytime you have a \n",
    "# TypeError: super(type, obj): obj must be an instance or subtype of type\n",
    "from scale import *\n",
    "from feature import *\n",
    "from tools import *\n",
    "from score import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Dataframe wrapper and highlight function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyDataFrame(object):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.list_df = [df]\n",
    "        self.n_updates = 0\n",
    "    def update(self,df):\n",
    "        self.df = df\n",
    "        self.list_df+=[df]\n",
    "        self.n_updates += 1\n",
    "    def last_indices_removed(self):\n",
    "        return self.list_df[-2].index.difference(self.list_df[-1].index)\n",
    "    def __str__(self):            \n",
    "        return str(len(self.df))  if (len(self.df)<=999) else \">999\"\n",
    "\n",
    "# Style should be an attribute of the dataframe\n",
    "    \n",
    "def highlight_not_null(df_colors=['green'], null_color='red',unknown_color='white'):\n",
    "    def style_function(s):\n",
    "        colors = []\n",
    "        for p in s: \n",
    "            if pd.isnull(p):\n",
    "                colors+=[null_color]\n",
    "            elif type(p) is MyDataFrame:\n",
    "                colors+=[df_colors[p.n_updates]]\n",
    "            else:\n",
    "                colors+=[unknown_color]\n",
    "        return ['background-color: '+color for color in colors]\n",
    "    return style_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scales_tag = [\"10m\",\"3h\",\"6h\",\"1d\",\"7d\",\"30d\",\"180d\"]\n",
    "features_tag = [\"trend\",\"step\",\"spike\",\"oscillation\",\"correlation\"]\n",
    "features_df = pd.DataFrame(index=features_tag,columns=scales_tag,dtype=np.float64)\n",
    "features_df.style.apply(highlight_not_null(['yellow']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define slice-resample functions\n",
    "\n",
    "This is to handle the fact that we resample the dataframe, and then split it according to the periods of interest.\n",
    "\n",
    "We remove the low regime, powering ups and powering downs of each cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_list_df(list_df, feature):\n",
    "    list_score_df = []\n",
    "    for df in list_df:\n",
    "        list_score_df += [feature.score(df,[deb1[0]])]\n",
    "    return pd.concat(list_score_df, axis=0)\n",
    "    \n",
    "def list_subsampled(obs, scale):\n",
    "    return obs.low_regime_intervals.split_between(scale.scale(obs.full_concatenated_df), time=timedelta(days=3))\n",
    "\n",
    "def scale_feature(scale, feature):\n",
    "    return score_list_df(list_subsampled(obs,scale),feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = [\n",
    "#     (\"trend\",\"1d\",HourScale(1), Trend(24)),  # 1 days\n",
    "#     (\"trend\",\"7d\",HourScale(6), Trend(28)),  # 7 days\n",
    "#     (\"trend\",\"30d\",DayScale(1), Trend(30)),  # 30 days\n",
    "#     (\"trend\",\"180d\",DayScale(6), Trend(30)),  # 180 days\n",
    "#     (\"step\",\"6h\",MinutesScale(), Step(36)), # 6 hours\n",
    "#     (\"step\",\"1d\",HourScale(1), Step(24)),   # 1 days\n",
    "#     (\"step\",\"7d\",HourScale(6), Step(28)),   # 7 days\n",
    "      (\"debCorr\",\"1d\",HourScale(1),MinCorrelationDeb(24)), #1 day\n",
    "#     (\"correlation\",\"6h\",MinutesScale(), Correlation(36)), # 6 hours\n",
    "#     (\"correlation\",\"1d\",HourScale(1), Correlation(24)),   # 1 days\n",
    "#     (\"correlation\",\"7d\",HourScale(6), Correlation(28)),   # 7 days\n",
    "#     (\"correlation\",\"30d\",DayScale(1), Correlation(30)),  # 30 days\n",
    "#     (\"spike\",\"10m\",MinutesScale(), Spike()),\n",
    "#     (\"oscillation\",\"3h\",MinutesScale(),Oscillation(3,18)),\n",
    "#     (\"oscillation\",\"6h\",MinutesScale(),Oscillation(3,36))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for rule_tag, scale_tag, scale, rule in features_list:\n",
    "    features_df.loc[rule_tag,scale_tag] = MyDataFrame(scale_feature(scale,rule))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_df.style.apply(highlight_not_null(['yellow']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a column, it's as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_df.loc[\"debCorr\"] = [None for scale in scales_tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to save a features dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/mehlman/Data/features_df.pkl', 'wb') as output:\n",
    "    pickle.dump(features_df, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scales_tag = [\"10m\",\"3h\",\"6h\",\"1d\",\"7d\",\"30d\",\"180d\"]\n",
    "scores_tag = [\"trend_up\",\"trend_down\",\"step\",\"spike\",\"oscillation\",\"debCorr\"]\n",
    "scores_kept_df = pd.DataFrame(index=scores_tag,columns=scales_tag,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scale_tag in scales_tag:\n",
    "    trend_feature = features_df.loc[\"trend\",scale_tag]\n",
    "    scores_kept_df.loc[\"trend_up\",scale_tag] = np.nan if pd.isnull(trend_feature) else MyDataFrame(trend_feature.df)\n",
    "    scores_kept_df.loc[\"trend_down\",scale_tag] = np.nan if pd.isnull(trend_feature) else MyDataFrame(-trend_feature.df)\n",
    "    \n",
    "    step_feature = features_df.loc[\"step\",scale_tag]\n",
    "    scores_kept_df.loc[\"step\",scale_tag] = np.nan if pd.isnull(step_feature) else MyDataFrame(step_feature.df.abs())\n",
    "    \n",
    "    spike_feature = features_df.loc[\"spike\",scale_tag]\n",
    "    scores_kept_df.loc[\"spike\",scale_tag] = np.nan if pd.isnull(spike_feature) else MyDataFrame(spike_feature.df)\n",
    "    \n",
    "    oscillation_feature = features_df.loc[\"oscillation\",scale_tag]\n",
    "    scores_kept_df.loc[\"oscillation\",scale_tag] = np.nan if pd.isnull(oscillation_feature) else MyDataFrame(oscillation_feature.df)\n",
    "        \n",
    "    debCorr_feature = features_df.loc[\"debCorr\",scale_tag]\n",
    "    scores_kept_df.loc[\"debCorr\",scale_tag] = np.nan if pd.isnull(debCorr_feature) else MyDataFrame(1-debCorr_feature.df.abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the scores dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors_scores_kept = [\"#3afffb\",\"#1ecebc\",\"#25ed75\",\"#26ad5c\",\"#26ad5c\",\"#26ad5c\"]\n",
    "scores_kept_df.style.apply(highlight_not_null(colors_scores_kept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_list = [\n",
    "    (\"trend_up\",\"1d\",ScoreAnalysis(2,timedelta(days=1))),  # 1 days\n",
    "    (\"trend_up\",\"7d\",ScoreAnalysis(2,timedelta(days=7))),  # 7 days\n",
    "    (\"trend_up\",\"30d\",ScoreAnalysis(2,timedelta(days=30))),  # 30 days\n",
    "    (\"trend_up\",\"180d\",ScoreAnalysis(2,timedelta(days=180))),  # 180 days\n",
    "    (\"trend_down\",\"1d\",ScoreAnalysis(2,timedelta(days=1))),  # 1 days\n",
    "    (\"trend_down\",\"7d\",ScoreAnalysis(2,timedelta(days=7))),  # 7 days\n",
    "    (\"trend_down\",\"30d\",ScoreAnalysis(2,timedelta(days=30))),  # 30 days\n",
    "    (\"trend_down\",\"180d\",ScoreAnalysis(2,timedelta(days=180))),  # 180 days\n",
    "    (\"step\",\"6h\",ScoreAnalysis(50,timedelta(hours=6))), # 6 hours\n",
    "    (\"step\",\"1d\",ScoreAnalysis(50,timedelta(days=1))),   # 1 days\n",
    "    (\"step\",\"7d\",ScoreAnalysis(50,timedelta(days=7))),   # 7 days\n",
    "    (\"spike\",\"10m\",ScoreAnalysis(100,timedelta(hours=3))),\n",
    "    (\"oscillation\",\"3h\",ScoreAnalysis(350,timedelta(hours=5))),\n",
    "    (\"debCorr\",\"1d\",ScoreAnalysis(0.8,timedelta(days=1)))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute analysis\n",
    "\n",
    "Here, we **update** the objects in `scores_kept_df` so that we keep track of the evolution of everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for rule_tag, scale_tag, analysis in analysis_list:\n",
    "    df_score = scores_kept_df.loc[rule_tag,scale_tag].df\n",
    "    scores_kept_df.loc[rule_tag,scale_tag].update(analysis.analyse_and_sort(df_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the modified scores dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_kept_df.style.apply(highlight_not_null(colors_scores_kept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Combine all results\n",
    "\n",
    "#### Remove overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_overlapping(obj_list,widths):\n",
    "    for obj, new_score in zip(obj_list, combine([obj.df for obj in obj_list],[],widths)):\n",
    "        obj.update(new_score)\n",
    "\n",
    "widths = [timedelta(days=1),timedelta(days=7),timedelta(days=30),timedelta(days=180)]\n",
    "remove_overlapping(scores_kept_df.loc[\"trend_up\"].dropna().values,widths)\n",
    "remove_overlapping(scores_kept_df.loc[\"trend_down\"].dropna().values,widths)\n",
    "\n",
    "widths = [timedelta(hours=6),timedelta(days=1),timedelta(days=7),timedelta(days=30)]\n",
    "remove_overlapping(scores_kept_df.loc[\"step\"].dropna().values,widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_kept_df.style.apply(highlight_not_null(colors_scores_kept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove inclusions\n",
    "\n",
    "Step up $\\subset $ Increasing Trend\n",
    "\n",
    "Step down $\\subset $ Decreasing Trend\n",
    "\n",
    "Spike $\\bigcap $ Oscillation $\\neq \\varnothing$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_df(scores_to_update,scores_exempt,widths,multiply = None):\n",
    "    df_updates = combine([obj.df for obj in scores_to_update],[obj.df for obj in scores_exempt],widths,multiply)\n",
    "    for s,df in zip(scores_to_update,df_updates):\n",
    "        s.update(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_to_update = [scores_kept_df.loc[\"trend_up\",\"1d\"],scores_kept_df.loc[\"trend_down\",\"1d\"],\n",
    "                   scores_kept_df.loc[\"trend_up\",\"7d\"],scores_kept_df.loc[\"trend_down\",\"7d\"]] \n",
    "scores_exempt = [scores_kept_df.loc[\"step\",\"6h\"],scores_kept_df.loc[\"step\",\"1d\"],scores_kept_df.loc[\"step\",\"7d\"]]\n",
    "widths = [timedelta(days=0),timedelta(days=0),timedelta(days=0),timedelta(days=0),timedelta(hours=6),timedelta(days=1),timedelta(days=7)]\n",
    "\n",
    "update_df(scores_to_update,scores_exempt,widths)\n",
    "\n",
    "scores_to_update = [scores_kept_df.loc[\"spike\",\"10m\"]]\n",
    "scores_exempt = [scores_kept_df.loc[\"oscillation\",\"3h\"]]\n",
    "widths = [timedelta(days=0),timedelta(hours=3)]\n",
    "\n",
    "update_df(scores_to_update,scores_exempt,widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_kept_df.style.apply(highlight_not_null(colors_scores_kept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load\n",
    "\n",
    "To save and load this final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('/home/mehlman/Data/scores_kept_df.pkl', 'wb') as output:\n",
    "#     pickle.dump(scores_kept_df, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('/home/mehlman/Data/scores_kept_df.pkl', 'rb') as input:\n",
    "#     scores_kept_df_2 = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "We can simply inspect our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from interval import Interval\n",
    "\n",
    "anomaly_indices = scores_kept_df.loc[\"debCorr\",\"1d\"].df.index.tolist()\n",
    "indices = Interval(anomaly_indices,timedelta(hours=12)).intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "begin,end = indices[50]\n",
    "obs.full_concatenated_df[begin:end][deb1].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the last indices removed; to check that we have **separated the trends from the steps**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_indices_removed = scores_kept_df.loc[\"trend_up\",\"7d\"].last_indices_removed().tolist()\n",
    "indices = Interval(last_indices_removed,timedelta(days=3)).intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "begin,end = indices[0]\n",
    "obs.full_concatenated_df[begin:end][deb1[0]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from interval import Interval\n",
    "\n",
    "test = Interval(scores_kept_df.loc[\"spike\",\"10m\"].df.index.tolist(), timedelta(days=1))\n",
    "begin, end = test.intervals[5,0], test.intervals[10,0]\n",
    "test.intervals_in([begin, end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def plot_portion(df, width, period,color='red', alpha = 0.3, lw = 4.0):\n",
    "    begin, end  = period\n",
    "    interval_object = Interval(df.index.tolist(), width)\n",
    "    for begin,end in interval_object.intervals_in([begin, end]):\n",
    "        obs.full_concatenated_df[deb1[0]][begin:end].plot(color=color, alpha = alpha, lw = lw) \n",
    "\n",
    "def plot_anomalies_for_period(periods):\n",
    "    obs.full_concatenated_df[deb1[0]][period[0]:period[1]].plot(color='grey')\n",
    "    plot_portion(scores_kept_df.loc[\"spike\",\"10m\"].df,timedelta(minutes = 10),period,color='yellow',alpha = 0.6)\n",
    "    plot_portion(scores_kept_df.loc[\"oscillation\",\"3h\"].df,timedelta(hours = 2),period,color='k',alpha = 0.8)\n",
    "    plot_portion(scores_kept_df.loc[\"trend_up\",\"1d\"].df,timedelta(hours = 12),period, color='#006600')\n",
    "    plot_portion(scores_kept_df.loc[\"trend_up\",\"7d\"].df,timedelta(days = 3),period, color='#00ff00', alpha = 0.5)\n",
    "    plot_portion(scores_kept_df.loc[\"trend_up\",\"30d\"].df,timedelta(days = 15),period, color='#80ff80', alpha = 0.5)\n",
    "    plot_portion(scores_kept_df.loc[\"trend_down\",\"1d\"].df,timedelta(days = 1),period, color='#660000')\n",
    "    plot_portion(scores_kept_df.loc[\"trend_down\",\"7d\"].df,timedelta(days = 3),period, color='#ff0000', alpha = 0.5)\n",
    "    plot_portion(scores_kept_df.loc[\"trend_down\",\"30d\"].df,timedelta(days = 15),period, color='#ff8080', alpha = 0.5)\n",
    "    plot_portion(scores_kept_df.loc[\"trend_down\",\"180d\"].df,timedelta(days = 90),period, color='#ff8080', alpha = 0.2)\n",
    "    plot_portion(scores_kept_df.loc[\"step\",\"6h\"].df,timedelta(hours = 2),period, color='#000066')\n",
    "    plot_portion(scores_kept_df.loc[\"step\",\"1d\"].df,timedelta(hours = 12),period, color='#0000ff', alpha = 0.5)\n",
    "    plot_portion(scores_kept_df.loc[\"step\",\"7d\"].df,timedelta(days = 3),period, color='#8080ff', alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "period = (datetime(2008, 9, 5),datetime(2009,2, 5))  \n",
    "plot_anomalies_for_period(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "period = (datetime(2011, 2, 1),datetime(2012, 1, 1)) \n",
    "plot_anomalies_for_period(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rolling_size = 10\n",
    "a1 = obs.full_concatenated_df[deb1[0]].tail(100).values\n",
    "a2 = obs.full_concatenated_df[deb1[1]].tail(100).values\n",
    "a3 = obs.full_concatenated_df[deb1[2]].tail(100).values\n",
    "np.corrcoef([a1,a2,a3]).min()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tsc]",
   "language": "python",
   "name": "conda-env-tsc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
