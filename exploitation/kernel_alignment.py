"""
Given an matrix representing a multivariate time series and a window length w_length,
Compute an anomaly vector that asssociates an anomaly score for each subsequence of the data.
This algorithm is very costly though.
"""
import unittest
import numpy as np
import pandas as pd

def kernel_matrix_predictors(multivariate_series,w_length):
    ts_length = len(multivariate_series)
    matrix_shape = ts_length - w_length + 1
    sigma = np.var(multivariate_series)
    K = np.identity(matrix_shape)
    for i in range(matrix_shape):
        for j in range(0, i):
            K[i, j] = K[j, i] = np.exp(
                -np.sum(np.power(multivariate_series[i:i + w_length, :] - multivariate_series[j:j + w_length, :], 2)) / sigma)
    return K

def kernel_matrix_target(series,w_length):
    ts_length = len(series)
    matrix_shape = ts_length - w_length + 1
    K = np.identity(matrix_shape)
    for i in range(matrix_shape):
        for j in range(0, i):
            K[i, j] = K[j, i] = np.sum(series[i:i + w_length, :]*series[j:j + w_length, :])
    return K

def transition_matrix(kernel_matrix):
    # Normalization is as proposed in the paper.
    return kernel_matrix/np.sum(kernel_matrix,axis = 1)[:, np.newaxis]

def kernel_align(predictors, y, w_length = 25):
    ts_length = len(y)
    matrix_shape = ts_length - w_length + 1
    print("Predictors kernel Matrix creation (K_X) ")
    K_X = kernel_matrix_predictors(predictors,w_length)
    print("Target kernel Matrix creation (K_Y)")
    # According to the paper kernel_matrix_predictors is not used for y
    # But it gives negative values for the matrix, which is strange.
    K_Y = kernel_matrix_target(y,w_length)
    print("Diagonalisation Predictors kernel Matrix (K_X)")
    w,v = np.linalg.eig(K_X)
    mu = 1.0 # hyperparameter to avoid overfitting

    print("Computing K_hat")
    # The matrices used for computing the aligned matrix
    K_X_decomposition = np.array([np.dot(v[:, [i]], v[:, [i]].T) for i in range(matrix_shape)])
    # Closed form solution with Froebenius product
    alpha = np.array([w[j] + np.sum(K_X_decomposition[j]*K_Y)/(2*mu) for j in range(matrix_shape)])
    K_hat = np.sum(np.array([K_X_decomposition[i]*alpha[i] for i in range(matrix_shape)]),axis=0)
    return K_hat

def connectivity_factor(transition_matrix, d = 0.1, n_iter = 100):
    matrix_shape = len(transition_matrix)
    connectivity = np.ones(matrix_shape)/matrix_shape
    for i in range(n_iter):
        connectivity = d/matrix_shape + (1-d)*np.dot(transition_matrix,connectivity)
    return connectivity

class TestKernelAlignement(unittest.TestCase):

    def test_kernel_align(self):
        predictors = np.array([[1, 2], [3, 4], [5, 6], [5, 6], [1, 2], [3, 4]])
        y = np.array([[1], [3], [5], [1], [3], [5]])
        K_X = kernel_matrix_predictors(predictors, w_length = 1)
        self.assertEqual(K_X[2, 2], 1.0)
        self.assertEqual(K_X[2, 3], 1.0)
        self.assertEqual(K_X[0, 4], 1.0)
        K_X = kernel_matrix_predictors(predictors, w_length=2)
        self.assertEqual(K_X[0, 4], 1.0)
        self.assertEqual(K_X.shape, (5,5))

if __name__ == '__main__':
    unittest.main()